<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>lib.fmetrics</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="lib-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            >BreastCancerWisconsin</th>
          </tr></table></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">
      <span class="breadcrumbs">
        <a href="lib-module.html">Package&nbsp;lib</a> ::
        Module&nbsp;fmetrics
      </span>
    </td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options">[<a href="javascript:void(0);" class="privatelink"
    onclick="toggle_private();">hide&nbsp;private</a>]</span></td></tr>
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="lib.fmetrics-pysrc.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<h1 class="epydoc">Source Code for <a href="lib.fmetrics-module.html">Module lib.fmetrics</a></h1>
<pre class="py-src">
<a name="L1"></a><tt class="py-lineno">  1</tt>  <tt class="py-line"><tt class="py-docstring">"""</tt> </tt>
<a name="L2"></a><tt class="py-lineno">  2</tt>  <tt class="py-line"><tt class="py-docstring">@created_at 2014-10-08</tt> </tt>
<a name="L3"></a><tt class="py-lineno">  3</tt>  <tt class="py-line"><tt class="py-docstring">@author Exequiel Fuentes &lt;efulet@gmail.com&gt;</tt> </tt>
<a name="L4"></a><tt class="py-lineno">  4</tt>  <tt class="py-line"><tt class="py-docstring">"""</tt> </tt>
<a name="L5"></a><tt class="py-lineno">  5</tt>  <tt class="py-line"> </tt>
<a name="L6"></a><tt class="py-lineno">  6</tt>  <tt class="py-line"><tt class="py-comment"># Se recomienda seguir los siguientes estandares:</tt> </tt>
<a name="L7"></a><tt class="py-lineno">  7</tt>  <tt class="py-line"><tt class="py-comment">#   1. Para codificacion: PEP 8 - Style Guide for Python Code (http://legacy.python.org/dev/peps/pep-0008/)</tt> </tt>
<a name="L8"></a><tt class="py-lineno">  8</tt>  <tt class="py-line"><tt class="py-comment">#   2. Para documentacion: PEP 257 - Docstring Conventions (http://legacy.python.org/dev/peps/pep-0257/)</tt> </tt>
<a name="L9"></a><tt class="py-lineno">  9</tt>  <tt class="py-line"> </tt>
<a name="L10"></a><tt class="py-lineno"> 10</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">sklearn</tt> <tt class="py-keyword">import</tt> <tt class="py-name">metrics</tt> </tt>
<a name="L11"></a><tt class="py-lineno"> 11</tt>  <tt class="py-line"> </tt>
<a name="L12"></a><tt class="py-lineno"> 12</tt>  <tt class="py-line"> </tt>
<a name="FMetrics"></a><div id="FMetrics-def"><a name="L13"></a><tt class="py-lineno"> 13</tt> <a class="py-toggle" href="#" id="FMetrics-toggle" onclick="return toggle('FMetrics');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="lib.fmetrics.FMetrics-class.html">FMetrics</a><tt class="py-op">:</tt> </tt>
</div><div id="FMetrics-collapsed" style="display:none;" pad="+++" indent="++++"></div><div id="FMetrics-expanded"><a name="L14"></a><tt class="py-lineno"> 14</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L15"></a><tt class="py-lineno"> 15</tt>  <tt class="py-line"><tt class="py-docstring">    Encapsulate metrics for reporting via console</tt> </tt>
<a name="L16"></a><tt class="py-lineno"> 16</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L17"></a><tt class="py-lineno"> 17</tt>  <tt class="py-line">     </tt>
<a name="FMetrics.__init__"></a><div id="FMetrics.__init__-def"><a name="L18"></a><tt class="py-lineno"> 18</tt> <a class="py-toggle" href="#" id="FMetrics.__init__-toggle" onclick="return toggle('FMetrics.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="lib.fmetrics.FMetrics-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FMetrics.__init__-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FMetrics.__init__-expanded"><a name="L19"></a><tt class="py-lineno"> 19</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L20"></a><tt class="py-lineno"> 20</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
</div><a name="L21"></a><tt class="py-lineno"> 21</tt>  <tt class="py-line">     </tt>
<a name="FMetrics.apparent_error_rate"></a><div id="FMetrics.apparent_error_rate-def"><a name="L22"></a><tt class="py-lineno"> 22</tt> <a class="py-toggle" href="#" id="FMetrics.apparent_error_rate-toggle" onclick="return toggle('FMetrics.apparent_error_rate');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="lib.fmetrics.FMetrics-class.html#apparent_error_rate">apparent_error_rate</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">y_train</tt><tt class="py-op">,</tt> <tt class="py-param">y_train_pred</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FMetrics.apparent_error_rate-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FMetrics.apparent_error_rate-expanded"><a name="L23"></a><tt class="py-lineno"> 23</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L24"></a><tt class="py-lineno"> 24</tt>  <tt class="py-line"><tt class="py-docstring">        Calculate Apparent error rate</tt> </tt>
<a name="L25"></a><tt class="py-lineno"> 25</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L26"></a><tt class="py-lineno"> 26</tt>  <tt class="py-line">        <tt class="py-name">error</tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt> </tt>
<a name="L27"></a><tt class="py-lineno"> 27</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">i</tt> <tt class="py-keyword">in</tt> <tt class="py-name">range</tt><tt class="py-op">(</tt><tt class="py-number">0</tt><tt class="py-op">,</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">y_train_pred</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L28"></a><tt class="py-lineno"> 28</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">y_train</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt> <tt class="py-op">!=</tt> <tt class="py-name">y_train_pred</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">:</tt> <tt class="py-name">error</tt> <tt class="py-op">+=</tt> <tt class="py-number">1</tt> </tt>
<a name="L29"></a><tt class="py-lineno"> 29</tt>  <tt class="py-line">         </tt>
<a name="L30"></a><tt class="py-lineno"> 30</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-name">float</tt><tt class="py-op">(</tt><tt class="py-name">error</tt><tt class="py-op">)</tt><tt class="py-op">/</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">y_train_pred</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L31"></a><tt class="py-lineno"> 31</tt>  <tt class="py-line">     </tt>
<a name="FMetrics.report"></a><div id="FMetrics.report-def"><a name="L32"></a><tt class="py-lineno"> 32</tt> <a class="py-toggle" href="#" id="FMetrics.report-toggle" onclick="return toggle('FMetrics.report');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="lib.fmetrics.FMetrics-class.html#report">report</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">y_train</tt><tt class="py-op">,</tt> <tt class="py-param">y_train_pred</tt><tt class="py-op">,</tt> <tt class="py-param">y_test</tt><tt class="py-op">,</tt> <tt class="py-param">y_pred</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FMetrics.report-collapsed" style="display:none;" pad="+++" indent="++++++++"></div><div id="FMetrics.report-expanded"><a name="L33"></a><tt class="py-lineno"> 33</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L34"></a><tt class="py-lineno"> 34</tt>  <tt class="py-line"><tt class="py-docstring">        Create a report with several metrics</tt> </tt>
<a name="L35"></a><tt class="py-lineno"> 35</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L36"></a><tt class="py-lineno"> 36</tt>  <tt class="py-line">        <tt class="py-comment"># **********************************************************************</tt> </tt>
<a name="L37"></a><tt class="py-lineno"> 37</tt>  <tt class="py-line">        <tt class="py-comment"># Tasa de error aparente: tasa de error obtenida al clasificar las mismas </tt> </tt>
<a name="L38"></a><tt class="py-lineno"> 38</tt>  <tt class="py-line">        <tt class="py-comment"># instancias de entrenamiento.</tt> </tt>
<a name="L39"></a><tt class="py-lineno"> 39</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"Apparent error rate: %4f"</tt> <tt class="py-op">%</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-0" class="py-name" targets="Method lib.fmetrics.FMetrics.apparent_error_rate()=lib.fmetrics.FMetrics-class.html#apparent_error_rate"><a title="lib.fmetrics.FMetrics.apparent_error_rate" class="py-name" href="#" onclick="return doclink('link-0', 'apparent_error_rate', 'link-0');">apparent_error_rate</a></tt><tt class="py-op">(</tt><tt class="py-name">y_train</tt><tt class="py-op">,</tt> <tt class="py-name">y_train_pred</tt><tt class="py-op">)</tt> </tt>
<a name="L40"></a><tt class="py-lineno"> 40</tt>  <tt class="py-line">         </tt>
<a name="L41"></a><tt class="py-lineno"> 41</tt>  <tt class="py-line">        <tt class="py-comment"># **********************************************************************</tt> </tt>
<a name="L42"></a><tt class="py-lineno"> 42</tt>  <tt class="py-line">        <tt class="py-comment"># The mean_absolute_error function computes the mean absolute error, </tt> </tt>
<a name="L43"></a><tt class="py-lineno"> 43</tt>  <tt class="py-line">        <tt class="py-comment"># which is a risk function corresponding to the expected value of the </tt> </tt>
<a name="L44"></a><tt class="py-lineno"> 44</tt>  <tt class="py-line">        <tt class="py-comment"># absolute error loss.</tt> </tt>
<a name="L45"></a><tt class="py-lineno"> 45</tt>  <tt class="py-line">        <tt class="py-comment"># Tasa de error verdadera: probabilidad de clasificar incorrectamente nuevos </tt> </tt>
<a name="L46"></a><tt class="py-lineno"> 46</tt>  <tt class="py-line">        <tt class="py-comment"># casos. Para ello se utiliza el conjunto de datos de prueba.</tt> </tt>
<a name="L47"></a><tt class="py-lineno"> 47</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"Mean absolute error: %.4f"</tt> <tt class="py-op">%</tt> <tt class="py-name">metrics</tt><tt class="py-op">.</tt><tt class="py-name">mean_absolute_error</tt><tt class="py-op">(</tt><tt class="py-name">y_test</tt><tt class="py-op">,</tt> <tt class="py-name">y_pred</tt><tt class="py-op">)</tt> </tt>
<a name="L48"></a><tt class="py-lineno"> 48</tt>  <tt class="py-line">         </tt>
<a name="L49"></a><tt class="py-lineno"> 49</tt>  <tt class="py-line">        <tt class="py-comment"># **********************************************************************</tt> </tt>
<a name="L50"></a><tt class="py-lineno"> 50</tt>  <tt class="py-line">        <tt class="py-comment"># The confusion_matrix function computes the confusion matrix to </tt> </tt>
<a name="L51"></a><tt class="py-lineno"> 51</tt>  <tt class="py-line">        <tt class="py-comment"># evaluate the accuracy on a classification problem</tt> </tt>
<a name="L52"></a><tt class="py-lineno"> 52</tt>  <tt class="py-line">        <tt class="py-name">cm</tt> <tt class="py-op">=</tt> <tt class="py-name">metrics</tt><tt class="py-op">.</tt><tt class="py-name">confusion_matrix</tt><tt class="py-op">(</tt><tt class="py-name">y_test</tt><tt class="py-op">,</tt> <tt class="py-name">y_pred</tt><tt class="py-op">)</tt> </tt>
<a name="L53"></a><tt class="py-lineno"> 53</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"Confusion matrix:"</tt> </tt>
<a name="L54"></a><tt class="py-lineno"> 54</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-name">cm</tt> </tt>
<a name="L55"></a><tt class="py-lineno"> 55</tt>  <tt class="py-line">         </tt>
<a name="L56"></a><tt class="py-lineno"> 56</tt>  <tt class="py-line">        <tt class="py-comment"># **********************************************************************</tt> </tt>
<a name="L57"></a><tt class="py-lineno"> 57</tt>  <tt class="py-line">        <tt class="py-comment"># The mean_squared_error function computes the mean square error, </tt> </tt>
<a name="L58"></a><tt class="py-lineno"> 58</tt>  <tt class="py-line">        <tt class="py-comment"># which is a risk function corresponding to the expected value of the </tt> </tt>
<a name="L59"></a><tt class="py-lineno"> 59</tt>  <tt class="py-line">        <tt class="py-comment"># squared error loss or quadratic loss</tt> </tt>
<a name="L60"></a><tt class="py-lineno"> 60</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"Mean square error: %.4f"</tt> <tt class="py-op">%</tt> <tt class="py-name">metrics</tt><tt class="py-op">.</tt><tt class="py-name">mean_squared_error</tt><tt class="py-op">(</tt><tt class="py-name">y_test</tt><tt class="py-op">,</tt> <tt class="py-name">y_pred</tt><tt class="py-op">)</tt> </tt>
<a name="L61"></a><tt class="py-lineno"> 61</tt>  <tt class="py-line">         </tt>
<a name="L62"></a><tt class="py-lineno"> 62</tt>  <tt class="py-line">        <tt class="py-comment"># Accuracy classification score.</tt> </tt>
<a name="L63"></a><tt class="py-lineno"> 63</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"Accuracy score: %.4f"</tt> <tt class="py-op">%</tt> <tt class="py-name">metrics</tt><tt class="py-op">.</tt><tt class="py-name">accuracy_score</tt><tt class="py-op">(</tt><tt class="py-name">y_test</tt><tt class="py-op">,</tt> <tt class="py-name">y_pred</tt><tt class="py-op">)</tt> </tt>
<a name="L64"></a><tt class="py-lineno"> 64</tt>  <tt class="py-line">         </tt>
<a name="L65"></a><tt class="py-lineno"> 65</tt>  <tt class="py-line">        <tt class="py-comment"># **********************************************************************</tt> </tt>
<a name="L66"></a><tt class="py-lineno"> 66</tt>  <tt class="py-line">        <tt class="py-comment"># Explained variance score: 1 is perfect prediction and 0 means that </tt> </tt>
<a name="L67"></a><tt class="py-lineno"> 67</tt>  <tt class="py-line">        <tt class="py-comment"># there is no linear relationship between X and Y.</tt> </tt>
<a name="L68"></a><tt class="py-lineno"> 68</tt>  <tt class="py-line">        <tt class="py-comment">#print 'Variance score: %.4f' % classifier.score(X_test, y_test)</tt> </tt>
<a name="L69"></a><tt class="py-lineno"> 69</tt>  <tt class="py-line">         </tt>
<a name="L70"></a><tt class="py-lineno"> 70</tt>  <tt class="py-line">        <tt class="py-comment"># The r2_score function computes R^2, the coefficient of determination. </tt> </tt>
<a name="L71"></a><tt class="py-lineno"> 71</tt>  <tt class="py-line">        <tt class="py-comment"># It provides a measure of how well future samples are likely to be </tt> </tt>
<a name="L72"></a><tt class="py-lineno"> 72</tt>  <tt class="py-line">        <tt class="py-comment"># predicted by the model.</tt> </tt>
<a name="L73"></a><tt class="py-lineno"> 73</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"The coefficient of determination: %.4f"</tt> <tt class="py-op">%</tt> <tt class="py-name">metrics</tt><tt class="py-op">.</tt><tt class="py-name">r2_score</tt><tt class="py-op">(</tt><tt class="py-name">y_test</tt><tt class="py-op">,</tt> <tt class="py-name">y_pred</tt><tt class="py-op">)</tt> </tt>
<a name="L74"></a><tt class="py-lineno"> 74</tt>  <tt class="py-line">         </tt>
<a name="L75"></a><tt class="py-lineno"> 75</tt>  <tt class="py-line">        <tt class="py-comment"># **********************************************************************</tt> </tt>
<a name="L76"></a><tt class="py-lineno"> 76</tt>  <tt class="py-line">        <tt class="py-comment"># Compute the recall. The recall is the ratio tp / (tp + fn) where tp </tt> </tt>
<a name="L77"></a><tt class="py-lineno"> 77</tt>  <tt class="py-line">        <tt class="py-comment"># is the number of true positives and fn the number of false negatives. </tt> </tt>
<a name="L78"></a><tt class="py-lineno"> 78</tt>  <tt class="py-line">        <tt class="py-comment"># The recall is intuitively the ability of the classifier to find all </tt> </tt>
<a name="L79"></a><tt class="py-lineno"> 79</tt>  <tt class="py-line">        <tt class="py-comment"># the positive samples.</tt> </tt>
<a name="L80"></a><tt class="py-lineno"> 80</tt>  <tt class="py-line">         </tt>
<a name="L81"></a><tt class="py-lineno"> 81</tt>  <tt class="py-line">        <tt class="py-comment"># Calculate metrics for each label, and find their unweighted mean. This </tt> </tt>
<a name="L82"></a><tt class="py-lineno"> 82</tt>  <tt class="py-line">        <tt class="py-comment"># does not take label imbalance into account.</tt> </tt>
<a name="L83"></a><tt class="py-lineno"> 83</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"Recall(macro): %.4f"</tt> <tt class="py-op">%</tt> <tt class="py-name">metrics</tt><tt class="py-op">.</tt><tt class="py-name">recall_score</tt><tt class="py-op">(</tt><tt class="py-name">y_test</tt><tt class="py-op">,</tt> <tt class="py-name">y_pred</tt><tt class="py-op">,</tt> <tt class="py-name">average</tt><tt class="py-op">=</tt><tt class="py-string">'macro'</tt><tt class="py-op">)</tt> </tt>
<a name="L84"></a><tt class="py-lineno"> 84</tt>  <tt class="py-line">         </tt>
<a name="L85"></a><tt class="py-lineno"> 85</tt>  <tt class="py-line">        <tt class="py-comment"># Calculate metrics globally by counting the total true positives, false </tt> </tt>
<a name="L86"></a><tt class="py-lineno"> 86</tt>  <tt class="py-line">        <tt class="py-comment"># negatives and false positives.</tt> </tt>
<a name="L87"></a><tt class="py-lineno"> 87</tt>  <tt class="py-line">        <tt class="py-comment">#print "Recall(micro): %.4f" % metrics.recall_score(y_test, y_pred, average='micro')</tt> </tt>
<a name="L88"></a><tt class="py-lineno"> 88</tt>  <tt class="py-line">         </tt>
<a name="L89"></a><tt class="py-lineno"> 89</tt>  <tt class="py-line">        <tt class="py-comment"># Calculate metrics for each label, and find their average, weighted by </tt> </tt>
<a name="L90"></a><tt class="py-lineno"> 90</tt>  <tt class="py-line">        <tt class="py-comment"># support (the number of true instances for each label). This alters </tt> </tt>
<a name="L91"></a><tt class="py-lineno"> 91</tt>  <tt class="py-line">        <tt class="py-comment"># 'macro' to account for label imbalance; it can result in an F-score </tt> </tt>
<a name="L92"></a><tt class="py-lineno"> 92</tt>  <tt class="py-line">        <tt class="py-comment"># that is not between precision and recall.</tt> </tt>
<a name="L93"></a><tt class="py-lineno"> 93</tt>  <tt class="py-line">        <tt class="py-comment">#print "Recall(weighted): %.4f" % metrics.recall_score(y_test, y_pred, average='weighted')</tt> </tt>
<a name="L94"></a><tt class="py-lineno"> 94</tt>  <tt class="py-line">         </tt>
<a name="L95"></a><tt class="py-lineno"> 95</tt>  <tt class="py-line">        <tt class="py-comment"># If None, the scores for each class are returned.</tt> </tt>
<a name="L96"></a><tt class="py-lineno"> 96</tt>  <tt class="py-line">        <tt class="py-comment">#print "Recall(None): ", metrics.recall_score(y_test, y_pred, average=None)</tt> </tt>
<a name="L97"></a><tt class="py-lineno"> 97</tt>  <tt class="py-line">         </tt>
<a name="L98"></a><tt class="py-lineno"> 98</tt>  <tt class="py-line">        <tt class="py-comment"># **********************************************************************</tt> </tt>
<a name="L99"></a><tt class="py-lineno"> 99</tt>  <tt class="py-line">        <tt class="py-comment"># true positive (TP)</tt> </tt>
<a name="L100"></a><tt class="py-lineno">100</tt>  <tt class="py-line">        <tt class="py-comment"># true negative (TN)</tt> </tt>
<a name="L101"></a><tt class="py-lineno">101</tt>  <tt class="py-line">        <tt class="py-comment"># false positive (FP)</tt> </tt>
<a name="L102"></a><tt class="py-lineno">102</tt>  <tt class="py-line">        <tt class="py-comment"># false negative (FN)</tt> </tt>
<a name="L103"></a><tt class="py-lineno">103</tt>  <tt class="py-line">        <tt class="py-comment"># sensitivity or true positive rate (TPR)</tt> </tt>
<a name="L104"></a><tt class="py-lineno">104</tt>  <tt class="py-line">        <tt class="py-comment">#     TPR = TP / P = TP / (TP + FN)</tt> </tt>
<a name="L105"></a><tt class="py-lineno">105</tt>  <tt class="py-line">        <tt class="py-comment"># specificity (SPC) or True Negative Rate</tt> </tt>
<a name="L106"></a><tt class="py-lineno">106</tt>  <tt class="py-line">        <tt class="py-comment">#     SPC = TN / N = TN / (FP + TN)</tt> </tt>
<a name="L107"></a><tt class="py-lineno">107</tt>  <tt class="py-line">         </tt>
<a name="L108"></a><tt class="py-lineno">108</tt>  <tt class="py-line">        <tt class="py-comment"># The function roc_curve computes the receiver operating characteristic </tt> </tt>
<a name="L109"></a><tt class="py-lineno">109</tt>  <tt class="py-line">        <tt class="py-comment"># curve, or ROC curve.</tt> </tt>
<a name="L110"></a><tt class="py-lineno">110</tt>  <tt class="py-line">        <tt class="py-comment"># A receiver operating characteristic (ROC), or simply ROC curve, is a </tt> </tt>
<a name="L111"></a><tt class="py-lineno">111</tt>  <tt class="py-line">        <tt class="py-comment"># graphical plot which illustrates the performance of a binary classifier </tt> </tt>
<a name="L112"></a><tt class="py-lineno">112</tt>  <tt class="py-line">        <tt class="py-comment"># system as its discrimination threshold is varied. It is created by </tt> </tt>
<a name="L113"></a><tt class="py-lineno">113</tt>  <tt class="py-line">        <tt class="py-comment"># plotting the fraction of true positives out of the positives </tt> </tt>
<a name="L114"></a><tt class="py-lineno">114</tt>  <tt class="py-line">        <tt class="py-comment"># (TPR = true positive rate) vs. the fraction of false positives out of </tt> </tt>
<a name="L115"></a><tt class="py-lineno">115</tt>  <tt class="py-line">        <tt class="py-comment"># the negatives (FPR = false positive rate), at various threshold settings. </tt> </tt>
<a name="L116"></a><tt class="py-lineno">116</tt>  <tt class="py-line">        <tt class="py-comment"># TPR is also known as sensitivity, and FPR is one minus the specificity </tt> </tt>
<a name="L117"></a><tt class="py-lineno">117</tt>  <tt class="py-line">        <tt class="py-comment"># or true negative rate.</tt> </tt>
<a name="L118"></a><tt class="py-lineno">118</tt>  <tt class="py-line">        <tt class="py-name">fpr</tt><tt class="py-op">,</tt> <tt class="py-name">tpr</tt><tt class="py-op">,</tt> <tt class="py-name">thresholds</tt> <tt class="py-op">=</tt> <tt class="py-name">metrics</tt><tt class="py-op">.</tt><tt class="py-name">roc_curve</tt><tt class="py-op">(</tt><tt class="py-name">y_test</tt><tt class="py-op">,</tt> <tt class="py-name">y_pred</tt><tt class="py-op">,</tt> <tt class="py-name">pos_label</tt><tt class="py-op">=</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L119"></a><tt class="py-lineno">119</tt>  <tt class="py-line">        <tt class="py-name">precision</tt><tt class="py-op">,</tt> <tt class="py-name">recall</tt><tt class="py-op">,</tt> <tt class="py-name">threshold</tt> <tt class="py-op">=</tt> <tt class="py-name">metrics</tt><tt class="py-op">.</tt><tt class="py-name">precision_recall_curve</tt><tt class="py-op">(</tt><tt class="py-name">y_test</tt><tt class="py-op">,</tt> <tt class="py-name">y_pred</tt><tt class="py-op">)</tt> </tt>
<a name="L120"></a><tt class="py-lineno">120</tt>  <tt class="py-line">         </tt>
<a name="L121"></a><tt class="py-lineno">121</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"Sensitivity:"</tt> </tt>
<a name="L122"></a><tt class="py-lineno">122</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-name">tpr</tt> </tt>
<a name="L123"></a><tt class="py-lineno">123</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"Specificity:"</tt> </tt>
<a name="L124"></a><tt class="py-lineno">124</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-name">fpr</tt> </tt>
<a name="L125"></a><tt class="py-lineno">125</tt>  <tt class="py-line">         </tt>
<a name="L126"></a><tt class="py-lineno">126</tt>  <tt class="py-line">        <tt class="py-comment">#print metrics.classification_report(y_test, y_pred)</tt> </tt>
<a name="L127"></a><tt class="py-lineno">127</tt>  <tt class="py-line">         </tt>
<a name="L128"></a><tt class="py-lineno">128</tt>  <tt class="py-line">        <tt class="py-comment"># **********************************************************************</tt> </tt>
<a name="L129"></a><tt class="py-lineno">129</tt>  <tt class="py-line">        <tt class="py-comment"># Compute the F-beta score. The F-beta score is the weighted harmonic </tt> </tt>
<a name="L130"></a><tt class="py-lineno">130</tt>  <tt class="py-line">        <tt class="py-comment"># mean of precision and recall, reaching its optimal value at 1 and its </tt> </tt>
<a name="L131"></a><tt class="py-lineno">131</tt>  <tt class="py-line">        <tt class="py-comment"># worst value at 0. The beta parameter determines the weight of precision </tt> </tt>
<a name="L132"></a><tt class="py-lineno">132</tt>  <tt class="py-line">        <tt class="py-comment"># in the combined score. beta &lt; 1 lends more weight to precision, while </tt> </tt>
<a name="L133"></a><tt class="py-lineno">133</tt>  <tt class="py-line">        <tt class="py-comment"># beta &gt; 1 favors recall (beta -&gt; 0 considers only precision, </tt> </tt>
<a name="L134"></a><tt class="py-lineno">134</tt>  <tt class="py-line">        <tt class="py-comment"># beta -&gt; inf only recall).</tt> </tt>
<a name="L135"></a><tt class="py-lineno">135</tt>  <tt class="py-line">        <tt class="py-comment">#print "F_{beta}(0.5): %.4f" % metrics.fbeta_score(y_test, y_pred, beta=0.5)</tt> </tt>
<a name="L136"></a><tt class="py-lineno">136</tt>  <tt class="py-line">         </tt>
<a name="L137"></a><tt class="py-lineno">137</tt>  <tt class="py-line">        <tt class="py-comment"># Compute precision, recall, F-measure and support for each class</tt> </tt>
<a name="L138"></a><tt class="py-lineno">138</tt>  <tt class="py-line">        <tt class="py-name">precision</tt><tt class="py-op">,</tt> <tt class="py-name">recall</tt><tt class="py-op">,</tt> <tt class="py-name">fbeta_score</tt><tt class="py-op">,</tt> <tt class="py-name">support</tt> <tt class="py-op">=</tt> \ </tt>
<a name="L139"></a><tt class="py-lineno">139</tt>  <tt class="py-line">            <tt class="py-name">metrics</tt><tt class="py-op">.</tt><tt class="py-name">precision_recall_fscore_support</tt><tt class="py-op">(</tt><tt class="py-name">y_test</tt><tt class="py-op">,</tt> <tt class="py-name">y_pred</tt><tt class="py-op">,</tt> \ </tt>
<a name="L140"></a><tt class="py-lineno">140</tt>  <tt class="py-line">                                                    <tt class="py-name">beta</tt><tt class="py-op">=</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-name">average</tt><tt class="py-op">=</tt><tt class="py-string">"macro"</tt><tt class="py-op">,</tt> <tt class="py-name">pos_label</tt><tt class="py-op">=</tt><tt class="py-number">0</tt><tt class="py-op">)</tt> </tt>
<a name="L141"></a><tt class="py-lineno">141</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"[class=0] F_{beta}(1): %.4f"</tt> <tt class="py-op">%</tt> <tt class="py-name">fbeta_score</tt> </tt>
<a name="L142"></a><tt class="py-lineno">142</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"[class=0] Support: %.4f"</tt> <tt class="py-op">%</tt> <tt class="py-name">support</tt> </tt>
<a name="L143"></a><tt class="py-lineno">143</tt>  <tt class="py-line">         </tt>
<a name="L144"></a><tt class="py-lineno">144</tt>  <tt class="py-line">        <tt class="py-name">precision</tt><tt class="py-op">,</tt> <tt class="py-name">recall</tt><tt class="py-op">,</tt> <tt class="py-name">fbeta_score</tt><tt class="py-op">,</tt> <tt class="py-name">support</tt> <tt class="py-op">=</tt> \ </tt>
<a name="L145"></a><tt class="py-lineno">145</tt>  <tt class="py-line">            <tt class="py-name">metrics</tt><tt class="py-op">.</tt><tt class="py-name">precision_recall_fscore_support</tt><tt class="py-op">(</tt><tt class="py-name">y_test</tt><tt class="py-op">,</tt> <tt class="py-name">y_pred</tt><tt class="py-op">,</tt> \ </tt>
<a name="L146"></a><tt class="py-lineno">146</tt>  <tt class="py-line">                                                    <tt class="py-name">beta</tt><tt class="py-op">=</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-name">average</tt><tt class="py-op">=</tt><tt class="py-string">"macro"</tt><tt class="py-op">,</tt> <tt class="py-name">pos_label</tt><tt class="py-op">=</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
<a name="L147"></a><tt class="py-lineno">147</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"[class=1] F_{beta}(1): %.4f"</tt> <tt class="py-op">%</tt> <tt class="py-name">fbeta_score</tt> </tt>
<a name="L148"></a><tt class="py-lineno">148</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-string">"[class=1] Support: %.4f"</tt> <tt class="py-op">%</tt> <tt class="py-name">support</tt> </tt>
</div></div><a name="L149"></a><tt class="py-lineno">149</tt>  <tt class="py-line"> </tt><script type="text/javascript">
<!--
expandto(location.href);
// -->
</script>
</pre>
<br />
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="lib-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            >BreastCancerWisconsin</th>
          </tr></table></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Fri Mar  6 11:53:37 2015
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
